{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras函数式(Functional)模型.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chongzicbo/keras_tutorial/blob/master/keras%E5%87%BD%E6%95%B0%E5%BC%8F(Functional)%E6%A8%A1%E5%9E%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjyEREgGUFK5",
        "colab_type": "text"
      },
      "source": [
        "##1. 第个模型：全连接网络\n",
        "首先弄清楚几个概念：\n",
        "* 层对象接受张量为参数，返回一个张量\n",
        "* 输入是张量，输出也是张量的一个框架就是一个模型，通过Model类定义。\n",
        "* 这样的模型可以被像Sequential一样被训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T7aP7OsVRO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input,Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o66mpvwVYff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs=Input(shape=(784,)) #Input会返回一个张量\n",
        "x=Dense(64,activation='relu')(inputs) #Input返回的向量作为Dense层的输入，Dense层也返回一个向量\n",
        "x=Dense(64,activation='relu')(x)\n",
        "predictions=Dense(10,activation='softmax')(x)\n",
        "\n",
        "#使用Model类创建一个模型\n",
        "model=Model(inputs=inputs,outputs=predictions)\n",
        "model.compile(optimizer='rmsprop',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmXiL5nWZZ8t",
        "colab_type": "text"
      },
      "source": [
        "创建训练数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSkoK-tfW9St",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsVxWeMHXp7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=(x_train.reshape((x_train.shape[0],x_train.shape[1]*x_train.shape[2])),y_train)\n",
        "test_data=(x_test.reshape((x_test.shape[0],x_test.shape[1]*x_test.shape[2])),y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQItr0FMZeKv",
        "colab_type": "text"
      },
      "source": [
        "开始训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-z3lemcXsM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "9ba8cb7b-6f9f-4392-a479-09ed79009364"
      },
      "source": [
        "model.fit(x=train_data[0],y=train_data[1],batch_size=256,epochs=10,validation_data=test_data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 3.4795 - acc: 0.8057 - val_loss: 0.9358 - val_acc: 0.8639\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 0.5623 - acc: 0.9007 - val_loss: 0.4798 - val_acc: 0.9076\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.3479 - acc: 0.9235 - val_loss: 0.3225 - val_acc: 0.9318\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2595 - acc: 0.9402 - val_loss: 0.4084 - val_acc: 0.9186\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2130 - acc: 0.9476 - val_loss: 0.3250 - val_acc: 0.9346\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 0.1881 - acc: 0.9546 - val_loss: 0.3079 - val_acc: 0.9361\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 0.1623 - acc: 0.9595 - val_loss: 0.2865 - val_acc: 0.9458\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 0.1516 - acc: 0.9627 - val_loss: 0.2350 - val_acc: 0.9525\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 0.1264 - acc: 0.9674 - val_loss: 0.2672 - val_acc: 0.9502\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1204 - acc: 0.9690 - val_loss: 0.2637 - val_acc: 0.9495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe6cf9f4c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgqAq2YwZNy1",
        "colab_type": "text"
      },
      "source": [
        "##2. 所有的模型都是可调用的，就像层一样\n",
        "利用函数式模型的接口，我们可以很容易的重用已经训练好的模型：你可以把模型当作一个层一样，通过提供一个tensor来调用它。注意当你调用一个模型时，你不仅仅重用了它的结构，也重用了它的权重。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0oX0mzeifew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=Input(shape=(784,))\n",
        "y=model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGXyrCntipUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import TimeDistributed\n",
        "\n",
        "#时间步长为20的输入向量，每个时间步的向量维度为784\n",
        "input_sequences=Input(shape=(20,784))\n",
        "#将之前的模型应用到输入序列的每一个时间步，最终的输出shape为[batch_size,20,10]\n",
        "processed_sequences=TimeDistributed(model)(input_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRne-XJPj3WA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "865b2c00-002f-49a7-cb09-0588f0c6282d"
      },
      "source": [
        "processed_sequences.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(20), Dimension(10)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D75Yqglzj4w4",
        "colab_type": "text"
      },
      "source": [
        "## 3.多输入和多输出模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz0FtnTwuGLo",
        "colab_type": "text"
      },
      "source": [
        "使用函数式模型的一个典型场景是搭建多输入、多输出的模型。\n",
        "\n",
        "考虑这样一个模型。我们希望预测Twitter上一条新闻会被转发和点赞多少次。模型的主要输入是新闻本身，也就是一个词语的序列。但我们还可以拥有额外的输入，如新闻发布的日期等。这个模型的损失函数将由两部分组成，辅助的损失函数评估仅仅基于新闻本身做出预测的情况，主损失函数评估基于新闻和额外信息的预测的情况，即使来自主损失函数的梯度发生弥散，来自辅助损失函数的信息也能够训练Embeddding和LSTM层。在模型中早点使用主要的损失函数是对于深度网络的一个良好的正则方法。总而言之，该模型框图如下：\n",
        "<center><img src=\"https://keras-cn.readthedocs.io/en/latest/images/multi-input-multi-output-graph.png\" width=\"300\"/></center>\n",
        "\n",
        "让我们用函数式模型来实现这个框图\n",
        "\n",
        "主要的输入接收新闻本身，即一个整数的序列（每个整数编码了一个词）。这些整数位于1到10，000之间（即我们的字典有10，000个词）。这个序列有100个单词。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFQMsEgZkNBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input,Embedding,LSTM,Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R19V-FK2mV3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#输入序列长度为100，序号再=在1-10000之间\n",
        "main_input=Input(shape=(100,),dtype='int32',name='main_input')\n",
        "#经过Embedding后，输出shape为(batch_size,input_length,output_dim)\n",
        "x=Embedding(output_dim=512,input_dim=10000,input_length=100)(main_input)\n",
        "#使用lstm进行编码，输出32个神经元\n",
        "lstm_out=LSTM(32)(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A_ocCxam_sP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "527ee261-5fe5-4e2e-abd0-d6538e74f521"
      },
      "source": [
        "lstm_out.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(32)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHmh-0bCuzl8",
        "colab_type": "text"
      },
      "source": [
        "然后，我们插入一个额外的损失，使得即使在主损失很高的情况下，LSTM和Embedding层也可以平滑的训练。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf2nxInpnDCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auxiliary_output=Dense(1,activation='sigmoid',name='aux_output')(lstm_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzFUPMeKu5b_",
        "colab_type": "text"
      },
      "source": [
        "再然后，我们将LSTM与额外的输入数据串联起来组成输入，送入模型中："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiilYhX0nRZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4f98640-1bac-4ca3-9322-ec81c3a291ce"
      },
      "source": [
        "auxiliary_input=Input(shape=(5,),name='aux_input')\n",
        "x=keras.layers.concatenate([lstm_out,auxiliary_input])\n",
        "x.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(37)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFqTYWIInpfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=Dense(64,activation='relu')(x)\n",
        "x=Dense(64,activation='relu')(x)\n",
        "x=Dense(64,activation='relu')(x)\n",
        "main_output=Dense(1,activation='sigmoid',name='main_output')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3WE_Sk9vqMg",
        "colab_type": "text"
      },
      "source": [
        "最后，我们定义整个2输入，2输出的模型："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klW2tY6avyvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Model(inputs=[main_input,auxiliary_input],outputs=[main_output,auxiliary_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_miJxdHoEBW",
        "colab_type": "text"
      },
      "source": [
        "创建假的数据集进行训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StMjcbt8oN4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_main=tf.reshape(tf.range(0,10000),shape=(100,100))\n",
        "y_main=tf.concat([tf.zeros(shape=(50)),tf.ones(shape=(50))],axis=0)\n",
        "\n",
        "x_auxiliary=tf.reshape(tf.range(0,500),shape=(100,5))\n",
        "y_auxiliary=tf.concat([tf.zeros(shape=(50)),tf.ones(shape=(50))],axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt7qzugbv-bj",
        "colab_type": "text"
      },
      "source": [
        "模型定义完毕，下一步编译模型。我们给额外的损失赋0.2的权重。我们可以通过关键字参数loss_weights或loss来为不同的输出设置不同的损失函数或权值。这两个参数均可为Python的列表或字典。这里我们给loss传递单个损失函数，这个损失函数会被应用于所有输出上。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElckjPOkpPJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5f95380-432e-4639-a46a-7defc3777361"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',loss_weights=[1.,0.2])\n",
        "model.fit(x=[x_main,x_auxiliary],y=[y_main,y_auxiliary],epochs=50,batch_size=10,steps_per_epoch=10)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10 samples\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 4s 435ms/step - loss: 2.3195 - main_output_loss: 2.2065 - aux_output_loss: 0.5646\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 3s 342ms/step - loss: 0.8313 - main_output_loss: 0.7815 - aux_output_loss: 0.2487\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 3s 345ms/step - loss: 0.6167 - main_output_loss: 0.5863 - aux_output_loss: 0.1518\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 3s 337ms/step - loss: 0.8276 - main_output_loss: 0.8082 - aux_output_loss: 0.0968\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 3s 349ms/step - loss: 0.0485 - main_output_loss: 0.0347 - aux_output_loss: 0.0688\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 3s 343ms/step - loss: 0.0132 - main_output_loss: 0.0033 - aux_output_loss: 0.0495\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 3s 334ms/step - loss: 0.0081 - main_output_loss: 0.0013 - aux_output_loss: 0.0343\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 3s 337ms/step - loss: 0.0053 - main_output_loss: 7.2326e-04 - aux_output_loss: 0.0227\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 3s 340ms/step - loss: 0.0033 - main_output_loss: 4.6959e-04 - aux_output_loss: 0.0143\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 3s 337ms/step - loss: 0.0020 - main_output_loss: 2.4691e-04 - aux_output_loss: 0.0088\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 3s 340ms/step - loss: 0.0013 - main_output_loss: 1.6774e-04 - aux_output_loss: 0.0055\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 3s 339ms/step - loss: 7.6094e-04 - main_output_loss: 5.6333e-05 - aux_output_loss: 0.0035\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 3s 347ms/step - loss: 4.9117e-04 - main_output_loss: 2.4968e-05 - aux_output_loss: 0.0023\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 3s 336ms/step - loss: 3.3491e-04 - main_output_loss: 1.2481e-05 - aux_output_loss: 0.0016\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 3s 339ms/step - loss: 2.4077e-04 - main_output_loss: 7.2984e-06 - aux_output_loss: 0.0012\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 3s 340ms/step - loss: 1.7966e-04 - main_output_loss: 4.4642e-06 - aux_output_loss: 8.7599e-04\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 3s 339ms/step - loss: 3.1839 - main_output_loss: 3.1838 - aux_output_loss: 6.5753e-04\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 3s 345ms/step - loss: 1.6059e-04 - main_output_loss: 5.3838e-05 - aux_output_loss: 5.3376e-04\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 3s 344ms/step - loss: 1.3323e-04 - main_output_loss: 4.6773e-05 - aux_output_loss: 4.3226e-04\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 3s 336ms/step - loss: 1.1094e-04 - main_output_loss: 4.1133e-05 - aux_output_loss: 3.4903e-04\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 3s 344ms/step - loss: 9.1226e-05 - main_output_loss: 3.4916e-05 - aux_output_loss: 2.8155e-04\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 3s 341ms/step - loss: 7.3968e-05 - main_output_loss: 2.8543e-05 - aux_output_loss: 2.2712e-04\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 3s 341ms/step - loss: 5.9193e-05 - main_output_loss: 2.2537e-05 - aux_output_loss: 1.8328e-04\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 3s 349ms/step - loss: 4.8524e-05 - main_output_loss: 1.8929e-05 - aux_output_loss: 1.4797e-04\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 3s 338ms/step - loss: 3.7014e-05 - main_output_loss: 1.3111e-05 - aux_output_loss: 1.1952e-04\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 3s 342ms/step - loss: 2.8976e-05 - main_output_loss: 9.6621e-06 - aux_output_loss: 9.6569e-05\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 3s 342ms/step - loss: 2.3157e-05 - main_output_loss: 7.5490e-06 - aux_output_loss: 7.8038e-05\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 3s 339ms/step - loss: 1.7177e-05 - main_output_loss: 4.5680e-06 - aux_output_loss: 6.3047e-05\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 3s 339ms/step - loss: 1.3219e-05 - main_output_loss: 3.0363e-06 - aux_output_loss: 5.0912e-05\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 3s 335ms/step - loss: 1.0210e-05 - main_output_loss: 1.9923e-06 - aux_output_loss: 4.1091e-05\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 3s 341ms/step - loss: 7.9502e-06 - main_output_loss: 1.3207e-06 - aux_output_loss: 3.3148e-05\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 3s 339ms/step - loss: 6.5081e-06 - main_output_loss: 1.1623e-06 - aux_output_loss: 2.6729e-05\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 3s 338ms/step - loss: 4.8612e-06 - main_output_loss: 5.5082e-07 - aux_output_loss: 2.1552e-05\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 3s 334ms/step - loss: 3.8407e-06 - main_output_loss: 3.6443e-07 - aux_output_loss: 1.7381e-05\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 3s 334ms/step - loss: 3.0398e-06 - main_output_loss: 2.3507e-07 - aux_output_loss: 1.4024e-05\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 3s 342ms/step - loss: 2.4315e-06 - main_output_loss: 1.6644e-07 - aux_output_loss: 1.1325e-05\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 3s 336ms/step - loss: 1.9274e-06 - main_output_loss: 9.5721e-08 - aux_output_loss: 9.1586e-06\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 3s 345ms/step - loss: 1.5471e-06 - main_output_loss: 6.3158e-08 - aux_output_loss: 7.4197e-06\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 3s 344ms/step - loss: 1.2451e-06 - main_output_loss: 4.0150e-08 - aux_output_loss: 6.0246e-06\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 3s 346ms/step - loss: 1.0071e-06 - main_output_loss: 2.6103e-08 - aux_output_loss: 4.9051e-06\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 3s 341ms/step - loss: 8.1848e-07 - main_output_loss: 1.7217e-08 - aux_output_loss: 4.0063e-06\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 3s 341ms/step - loss: 6.6955e-07 - main_output_loss: 1.2658e-08 - aux_output_loss: 3.2845e-06\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 3s 335ms/step - loss: 5.4934e-07 - main_output_loss: 8.5215e-09 - aux_output_loss: 2.7041e-06\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 3s 341ms/step - loss: 4.5343e-07 - main_output_loss: 6.0571e-09 - aux_output_loss: 2.2369e-06\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 3s 341ms/step - loss: 3.7692e-07 - main_output_loss: 4.9234e-09 - aux_output_loss: 1.8600e-06\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 3s 336ms/step - loss: 3.1538e-07 - main_output_loss: 4.2910e-09 - aux_output_loss: 1.5555e-06\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 3s 340ms/step - loss: 2.6576e-07 - main_output_loss: 4.0350e-09 - aux_output_loss: 1.3086e-06\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 3s 350ms/step - loss: 2.2527e-07 - main_output_loss: 3.6516e-09 - aux_output_loss: 1.1081e-06\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 3s 348ms/step - loss: 1.9659e-07 - main_output_loss: 7.6642e-09 - aux_output_loss: 9.4461e-07\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 3s 344ms/step - loss: 1.8570 - main_output_loss: 1.8570 - aux_output_loss: 7.7737e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe6c67f5710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB5QptFYqSWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "2c139f07-eee6-4036-d535-c8ebe952874e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "main_input (InputLayer)         [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 100, 512)     5120000     main_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           69760       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "aux_input (InputLayer)          [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 37)           0           lstm_1[0][0]                     \n",
            "                                                                 aux_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 64)           2432        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 64)           4160        dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 64)           4160        dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "main_output (Dense)             (None, 1)            65          dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "aux_output (Dense)              (None, 1)            33          lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 5,200,610\n",
            "Trainable params: 5,200,610\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjVKvhh0s3rd",
        "colab_type": "text"
      },
      "source": [
        "##4.共享层\n",
        "另一个使用函数式模型的场合是使用共享层的时候。\n",
        "\n",
        "考虑微博数据，我们希望建立模型来判别两条微博是否是来自同一个用户，这个需求同样可以用来判断一个用户的两条微博的相似性。\n",
        "\n",
        "一种实现方式是，我们建立一个模型，它分别将两条微博的数据映射到两个特征向量上，然后将特征向量串联并加一个logistic回归层，输出它们来自同一个用户的概率。这种模型的训练数据是一对对的微博。\n",
        "\n",
        "因为这个问题是对称的，所以处理第一条微博的模型当然也能重用于处理第二条微博。所以这里我们使用一个共享的LSTM层来进行映射。\n",
        "\n",
        "首先，我们将微博的数据转为（140，256）的矩阵，即每条微博有140个字符，每个单词的特征由一个256维的词向量表示，向量的每个元素为1表示某个字符出现，为0表示不出现，这是一个one-hot编码。\n",
        "\n",
        "之所以是（140，256）是因为一条微博最多有140个字符，而扩展的ASCII码表编码了常见的256个字符。原文中此处为Tweet，所以对外国人而言这是合理的。如果考虑中文字符，那一个单词的词向量就不止256了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJRpzkW77UW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet_a=Input(shape=(140,256))\n",
        "tweet_b=Input(shape=(140,256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oPLJeg77ljc",
        "colab_type": "text"
      },
      "source": [
        "若要对不同的输入共享同一层，就初始化该层一次，然后多次调用它"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieCyr2jk7ofD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shared_lstm=LSTM(64)\n",
        "encoded_a=shared_lstm(tweet_a)\n",
        "encoded_b=shared_lstm(tweet_b)\n",
        "merged_vector=keras.layers.concatenate([encoded_a,encoded_b],axis=-1)\n",
        "predictions=Dense(1,activation='sigmoid')(merged_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gevEpRpm8I8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Model(inputs=[tweet_a,tweet_b],outputs=predictions)\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5guhfa_U8h8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_a=tf.reshape(tf.range(start=0,limit=100*140*256),shape=(100,140,256))\n",
        "data_b=tf.reshape(tf.range(start=0,limit=100*140*256),shape=(100,140,256))\n",
        "labels=tf.concat([tf.zeros(shape=(50,)),tf.ones(shape=(50,))],axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BftcWU5x9onA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0e07f8bd-f209-4b4b-cf37-c23dac4cee9e"
      },
      "source": [
        "data_a.shape,data_b.shape,labels.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([Dimension(100), Dimension(140), Dimension(256)]),\n",
              " TensorShape([Dimension(100), Dimension(140), Dimension(256)]),\n",
              " TensorShape([Dimension(100)]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxoKMwDT9uos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit([data_a,data_b],labels,epochs=10,steps_per_epoch=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzJ-LyZi96u6",
        "colab_type": "text"
      },
      "source": [
        "##5. 层“节点”的概念\n",
        "无论何时，当你在某个输入上调用层时，你就创建了一个新的张量（即该层的输出），同时你也在为这个层增加一个“（计算）节点”。这个节点将输入张量映射为输出张量。当你多次调用该层时，这个层就有了多个节点，其下标分别为0，1，2...\n",
        "\n",
        "在上一版本的Keras中，你可以通过layer.get_output()方法来获得层的输出张量，或者通过layer.output_shape获得其输出张量的shape。这个版本的Keras你仍然可以这么做（除了layer.get_output()被output替换）。但如果一个层与多个输入相连，会出现什么情况呢？\n",
        "\n",
        "如果层只与一个输入相连，那没有任何困惑的地方。.output将会返回该层唯一的输出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnUlmbCR-rX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=Input(shape=(140,256))\n",
        "lstm=LSTM(32)\n",
        "encoded_a=lstm(a)\n",
        "assert lstm.output==encoded_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35rnxKSF_CTH",
        "colab_type": "text"
      },
      "source": [
        "但当层与多个输入相连时，会出现问题"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5KECGTU_Mwl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b86dc85-3362-4247-fedd-a83bb6cff4d6"
      },
      "source": [
        "a=Input(shape=(140,256))\n",
        "b=Input(shape=(140,256))\n",
        "lstm=LSTM(32)\n",
        "encoded_a=lstm(a)\n",
        "encoded_b=lstm(b)\n",
        "lstm.output #默认输出第一个节点：encoded_a"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'lstm_9/strided_slice_7:0' shape=(?, 32) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSTUiY2p_Z2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "953b9004-eab6-4c42-8f9a-25a373ac0675"
      },
      "source": [
        "lstm.get_output_at(0)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'lstm_7/strided_slice_7:0' shape=(?, 32) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiKobqVe_r4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert lstm.output==encoded_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI20G9-i_vHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a23ff8f3-301c-4e57-deec-827a4d5ad051"
      },
      "source": [
        "assert lstm.output==encoded_b"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-c91f9eb0b57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mencoded_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRdOy1FPAXkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}